import type { ModelDef } from "@koryphaios/shared";

/**
 * Ollama local models
 * Common models available through Ollama
 */
export const OllamaModels: ModelDef[] = [
  {
    id: "ollama.llama3.3",
    name: "Llama 3.3",
    provider: "ollama",
    apiModelId: "llama3.3",
    contextWindow: 128_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 0,
    costPerMOutputTokens: 0,
    canReason: false,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "ollama.llama3.2",
    name: "Llama 3.2",
    provider: "ollama",
    apiModelId: "llama3.2",
    contextWindow: 128_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 0,
    costPerMOutputTokens: 0,
    canReason: false,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "ollama.mistral",
    name: "Mistral",
    provider: "ollama",
    apiModelId: "mistral",
    contextWindow: 32_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 0,
    costPerMOutputTokens: 0,
    canReason: false,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "ollama.codellama",
    name: "CodeLlama",
    provider: "ollama",
    apiModelId: "codellama",
    contextWindow: 16_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 0,
    costPerMOutputTokens: 0,
    canReason: false,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "ollama.phi4",
    name: "Phi-4",
    provider: "ollama",
    apiModelId: "phi4",
    contextWindow: 16_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 0,
    costPerMOutputTokens: 0,
    canReason: false,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "fast",
  },
];
